{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TspH1wJmAkdk"
      },
      "source": [
        "### For the homeworks we are going to use the \"[Online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#)\"\n",
        "\n",
        "The dataset can be used both for regression and classification tasks.\n",
        "\n",
        "#### Source:\n",
        "\n",
        "Kelwin Fernandes INESC TEC, Porto, Portugal/Universidade do Porto, Portugal.\n",
        "Pedro Vinagre ALGORITMI Research Centre, Universidade do Minho, Portugal\n",
        "Paulo Cortez ALGORITMI Research Centre, Universidade do Minho, Portugal\n",
        "Pedro Sernadela Universidade de Aveiro\n",
        "\n",
        "#### Data Set Information:\n",
        "\n",
        "* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.\n",
        "* Acquisition date: January 8, 2015\n",
        "* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method. See their article for more details on how the relative performance values were set.\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "Number of Attributes: 61 (58 predictive attributes, 2 non-predictive, 1 goal field)\n",
        "\n",
        "Attribute Information:\n",
        "0. url: URL of the article (non-predictive)\n",
        "1. timedelta: Days between the article publication and the dataset acquisition (non-predictive)\n",
        "2. n_tokens_title: Number of words in the title\n",
        "3. n_tokens_content: Number of words in the content\n",
        "4. n_unique_tokens: Rate of unique words in the content\n",
        "5. n_non_stop_words: Rate of non-stop words in the content\n",
        "6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content\n",
        "7. num_hrefs: Number of links\n",
        "8. num_self_hrefs: Number of links to other articles published by Mashable\n",
        "9. num_imgs: Number of images\n",
        "10. num_videos: Number of videos\n",
        "11. average_token_length: Average length of the words in the content\n",
        "12. num_keywords: Number of keywords in the metadata\n",
        "13. data_channel_is_lifestyle: Is data channel 'Lifestyle'?\n",
        "14. data_channel_is_entertainment: Is data channel 'Entertainment'?\n",
        "15. data_channel_is_bus: Is data channel 'Business'?\n",
        "16. data_channel_is_socmed: Is data channel 'Social Media'?\n",
        "17. data_channel_is_tech: Is data channel 'Tech'?\n",
        "18. data_channel_is_world: Is data channel 'World'?\n",
        "19. kw_min_min: Worst keyword (min. shares)\n",
        "20. kw_max_min: Worst keyword (max. shares)\n",
        "21. kw_avg_min: Worst keyword (avg. shares)\n",
        "22. kw_min_max: Best keyword (min. shares)\n",
        "23. kw_max_max: Best keyword (max. shares)\n",
        "24. kw_avg_max: Best keyword (avg. shares)\n",
        "25. kw_min_avg: Avg. keyword (min. shares)\n",
        "26. kw_max_avg: Avg. keyword (max. shares)\n",
        "27. kw_avg_avg: Avg. keyword (avg. shares)\n",
        "28. self_reference_min_shares: Min. shares of referenced articles in Mashable\n",
        "29. self_reference_max_shares: Max. shares of referenced articles in Mashable\n",
        "30. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable\n",
        "31. weekday_is_monday: Was the article published on a Monday?\n",
        "32. weekday_is_tuesday: Was the article published on a Tuesday?\n",
        "33. weekday_is_wednesday: Was the article published on a Wednesday?\n",
        "34. weekday_is_thursday: Was the article published on a Thursday?\n",
        "35. weekday_is_friday: Was the article published on a Friday?\n",
        "36. weekday_is_saturday: Was the article published on a Saturday?\n",
        "37. weekday_is_sunday: Was the article published on a Sunday?\n",
        "38. is_weekend: Was the article published on the weekend?\n",
        "39. LDA_00: Closeness to LDA topic 0\n",
        "40. LDA_01: Closeness to LDA topic 1\n",
        "41. LDA_02: Closeness to LDA topic 2\n",
        "42. LDA_03: Closeness to LDA topic 3\n",
        "43. LDA_04: Closeness to LDA topic 4\n",
        "44. global_subjectivity: Text subjectivity\n",
        "45. global_sentiment_polarity: Text sentiment polarity\n",
        "46. global_rate_positive_words: Rate of positive words in the content\n",
        "47. global_rate_negative_words: Rate of negative words in the content\n",
        "48. rate_positive_words: Rate of positive words among non-neutral tokens\n",
        "49. rate_negative_words: Rate of negative words among non-neutral tokens\n",
        "50. avg_positive_polarity: Avg. polarity of positive words\n",
        "51. min_positive_polarity: Min. polarity of positive words\n",
        "52. max_positive_polarity: Max. polarity of positive words\n",
        "53. avg_negative_polarity: Avg. polarity of negative words\n",
        "54. min_negative_polarity: Min. polarity of negative words\n",
        "55. max_negative_polarity: Max. polarity of negative words\n",
        "56. title_subjectivity: Title subjectivity\n",
        "57. title_sentiment_polarity: Title polarity\n",
        "58. abs_title_subjectivity: Absolute subjectivity level\n",
        "59. abs_title_sentiment_polarity: Absolute polarity level\n",
        "60. shares: Number of shares (target)\n",
        "\n",
        "\n",
        "The first two columns (url and time_delta) are non-predictive and should be ignored\n",
        "\n",
        "The last column **shares** contains the value to predict.\n",
        "\n",
        "### Regression\n",
        "In the case of regression we want to predict the value of the share column.\n",
        "\n",
        "### Classification\n",
        "In the case of classification we want to predict one of two classes:\n",
        "\n",
        "* *low* -- shares < 1,400\n",
        "* *high* -- shares >= 1,400\n",
        "\n",
        "### Metrics\n",
        "\n",
        "#### Regression\n",
        "To evaluate how good we are doing on the **regression** task we will use the Root Mean Squared Error (RMSE). RMSE is given by\n",
        "\n",
        "$$\n",
        "\\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^{n}{\\Big(d_i -f_i\\Big)^2}}\n",
        "$$\n",
        "\n",
        "\n",
        "where:\n",
        "\n",
        "* $n$ is the number of test samples\n",
        "* $d_i$ is the ground truth value of the i-th sample\n",
        "* $f_i$ is the predicted value of the i-th sample\n",
        "\n",
        "\n",
        "#### Classification\n",
        "To evaluate how good we are doing on the **classification** task we will use the accuracy metrics. Accuracy is given by\n",
        "\n",
        "$$\n",
        "\\frac{TP+TN}{TP+TN+FP+FN}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "* TP is the number of *correctly* classified positive samples\n",
        "* TN is the number of *correctly* classified negative samples\n",
        "* FP is the number of *incorrectly* classified positive samples\n",
        "* FN is the number of *incorrectly* classified negative samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oesd6_bYijRo",
        "outputId": "20295a7b-77ba-4a2a-acb8-ed2c61817542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-27 10:32:22--  https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7476401 (7.1M) [application/x-httpd-php]\n",
            "Saving to: ‘OnlineNewsPopularity.zip’\n",
            "\n",
            "OnlineNewsPopularit 100%[===================>]   7.13M  15.7MB/s    in 0.5s    \n",
            "\n",
            "2023-05-27 10:32:23 (15.7 MB/s) - ‘OnlineNewsPopularity.zip’ saved [7476401/7476401]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmad6QdZ_nFR",
        "outputId": "9b39d187-ef72-4fb1-e25a-d58444636365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  OnlineNewsPopularity.zip\n",
            "   creating: OnlineNewsPopularity/\n",
            "  inflating: OnlineNewsPopularity/OnlineNewsPopularity.names  \n",
            "  inflating: OnlineNewsPopularity/OnlineNewsPopularity.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip OnlineNewsPopularity.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eW4t_c6ACcm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXCX_LpFedtj"
      },
      "source": [
        "Format properly the names of the columns and remove the first two columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mxntjhmAH0D"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "df = df.iloc[: , 2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCXwyljnAMmi",
        "outputId": "4098d198-c953-4347-9f9a-263a78c77667"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "n_tokens_title                   float64\n",
              "n_tokens_content                 float64\n",
              "n_unique_tokens                  float64\n",
              "n_non_stop_words                 float64\n",
              "n_non_stop_unique_tokens         float64\n",
              "num_hrefs                        float64\n",
              "num_self_hrefs                   float64\n",
              "num_imgs                         float64\n",
              "num_videos                       float64\n",
              "average_token_length             float64\n",
              "num_keywords                     float64\n",
              "data_channel_is_lifestyle        float64\n",
              "data_channel_is_entertainment    float64\n",
              "data_channel_is_bus              float64\n",
              "data_channel_is_socmed           float64\n",
              "data_channel_is_tech             float64\n",
              "data_channel_is_world            float64\n",
              "kw_min_min                       float64\n",
              "kw_max_min                       float64\n",
              "kw_avg_min                       float64\n",
              "kw_min_max                       float64\n",
              "kw_max_max                       float64\n",
              "kw_avg_max                       float64\n",
              "kw_min_avg                       float64\n",
              "kw_max_avg                       float64\n",
              "kw_avg_avg                       float64\n",
              "self_reference_min_shares        float64\n",
              "self_reference_max_shares        float64\n",
              "self_reference_avg_sharess       float64\n",
              "weekday_is_monday                float64\n",
              "weekday_is_tuesday               float64\n",
              "weekday_is_wednesday             float64\n",
              "weekday_is_thursday              float64\n",
              "weekday_is_friday                float64\n",
              "weekday_is_saturday              float64\n",
              "weekday_is_sunday                float64\n",
              "is_weekend                       float64\n",
              "LDA_00                           float64\n",
              "LDA_01                           float64\n",
              "LDA_02                           float64\n",
              "LDA_03                           float64\n",
              "LDA_04                           float64\n",
              "global_subjectivity              float64\n",
              "global_sentiment_polarity        float64\n",
              "global_rate_positive_words       float64\n",
              "global_rate_negative_words       float64\n",
              "rate_positive_words              float64\n",
              "rate_negative_words              float64\n",
              "avg_positive_polarity            float64\n",
              "min_positive_polarity            float64\n",
              "max_positive_polarity            float64\n",
              "avg_negative_polarity            float64\n",
              "min_negative_polarity            float64\n",
              "max_negative_polarity            float64\n",
              "title_subjectivity               float64\n",
              "title_sentiment_polarity         float64\n",
              "abs_title_subjectivity           float64\n",
              "abs_title_sentiment_polarity     float64\n",
              "shares                             int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu_rxzq0f2gV"
      },
      "source": [
        "## Let's plot some of the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VbFlnYRjAXlk",
        "outputId": "5a6299c4-40d5-455d-80a3-fa7b60f75472"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x2000 with 6 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "columns_to_plot = [\n",
        "    'num_videos',\n",
        "    'num_imgs',\n",
        "    'num_keywords',\n",
        "    'data_channel_is_world',\n",
        "    'rate_negative_words',\n",
        "    'self_reference_avg_sharess',\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(len(columns_to_plot), 1, figsize=(20, 20))\n",
        "\n",
        "for i, column in enumerate(columns_to_plot, 0):\n",
        "  ax[i].hist(df[column])\n",
        "  ax[i].title.set_text(column)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreUUCYinWBT"
      },
      "source": [
        "# Utili"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsoqy2omvIJA"
      },
      "source": [
        "Importo delle librerie utili per il funzionamento dei vari codici"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ar08x0cnaFE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVKnGpi7nefA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('OnlineNewsPopularity/OnlineNewsPopularity.csv')\n",
        "df = df.rename(columns=lambda x: x.strip())\n",
        "df = df.iloc[: , 2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3QJSZ2UC4DK"
      },
      "source": [
        "l'ultima colonna contiene gli shares che sono i valori da predirre. Separiamo le feature dal target e per comodità inserisco una colonna che classifica le shares come true o false in base se sono >=1400 o no, questa colonna sarà utile per i problemi di classificazione mentre userò la colonna originale per quelli di regressione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkp-9QdmDCI1",
        "outputId": "2caf14c7-c488-4342-8aa8-d7cada2df287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        False\n",
              "1        False\n",
              "2         True\n",
              "3        False\n",
              "4        False\n",
              "         ...  \n",
              "39639     True\n",
              "39640     True\n",
              "39641     True\n",
              "39642    False\n",
              "39643    False\n",
              "Name: higth, Length: 39644, dtype: bool"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up83cHz8Pj4T"
      },
      "source": [
        "accuracy per verificare l'accuratezza nel caso di classificazione\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk8xWysHPden"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVUtUstCiNa"
      },
      "source": [
        "Root Mean Squared Error (RMSE) per valutare la regressione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BK0vA3ECg_K"
      },
      "outputs": [],
      "source": [
        "def rmse(y, y_h):\n",
        "        error = 0\n",
        "        for i in range(len(y)):\n",
        "            diff=y[i]-y_h[i]\n",
        "            error += (diff) ** 2\n",
        "        return math.sqrt(error / len(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0U_QCzFhcNJ"
      },
      "source": [
        "# Decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0KboLqUvNW_"
      },
      "source": [
        "Preparo i dati per usarli nel decision tree.\n",
        "Nelle x metto le feature usando iloc[:,  :-2].values in questo modo escludo le ultime due colonne e considero solo i valori delle colonne prese da x.\n",
        "La y prende solo l'ultima colonna iloc[:, -1] ovvero la colonna di True e False.\n",
        "Poi usa sklearn per creare il train e il test in modo casuale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXuHQxrchjoD"
      },
      "outputs": [],
      "source": [
        "x = df.iloc[:, :-2].values\n",
        "\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, test_size=0.2, random_state=1234\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLnPMJJfwP49"
      },
      "source": [
        "Realizzo la classe Nodo per i miei alberi di decisione e nel caso di nodi leaf ovvero i nodi alla fine dell'albero ho un attributo di tipo value. Infatti nel caso il valore di value!=None allora è una foglia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h3Mc3lvhnyI"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "    def is_leaf_node(self):\n",
        "        return self.value is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YFTC-MxxPDl"
      },
      "source": [
        "realizzo il vero e proprio albero di decisione.\n",
        "* __init__(): è il costruttore, al suo interno imposto varie variabili tra cui le più importanti sono:\n",
        "    1. max_depth ovvero la profondità massima dell'albero da anlizzare.\n",
        "    2. min_samples_split il numero minimo di samples  necessari per dividere un nodo\n",
        "    3. features non usa tutte le features a disposizione ma solo una selezione\n",
        "\n",
        "*   build(x, y)la funzione costruisce in modo ricorsivo un albero decisionale in caso vengano rispettati i criteri di arresto si ferma la costruzione.\n",
        "Usa la funzione bestsplit per ricevere la miglior combinazione (split, threshold).\n",
        "Crea i nodi figli usando lo split() e poi costruisce l'albero ricorsivamente usando la funzione bulid().\n",
        "Alla fine restituisce il nodo\n",
        "*   fit(x, y) chiama la build() e memorizza l'albero costruito nel costruttore\n",
        "*   mc_label(self, y) restituisce il valore del target più presente\n",
        "*   bestsplit(self, x, y, feature)  calcola tutte le possibili combinazione  (rsplit, rthreshold) e restituisce la migliore usando information gain. Nel nostro caso selezioniamo le feature prendendole randomicamente dalle feature (n_f) disponibili per un numero pari a self.features\n",
        "*  infgain(self, y, xc, threshold) calcola l'information gain di uno split.\n",
        "Per prima cosa calcolo l'entropia del padre, usando la funzione split creo i due figli (destra e sinistra) se lo split è avvenuto con successo allora calcolo la media ponderata dell'entropia dei figli e la sottrae a quella del padre\n",
        "* entropy(self, y) calcola l'entropia\n",
        "*  split(self, x_column, thresh) divide gli elementi a seconda che siano > o <= del threshold (t). creando il ramo di destra e sinistra\n",
        "* predict(self, x) per ogni  xx in x applica la funzione ttree(), e restituisce un array di tali risultati\n",
        "* ttree(self, x, node) attraversa l'albero ricorsivamente per classificare una singola istanza. Controllo se è un nodo foglia in tal caso restituisco node.value.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVGXUyedrBvu"
      },
      "outputs": [],
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, min_samples_split=2, max_depth=100, features=None):\n",
        "        self.min_samples_split=min_samples_split\n",
        "        self.max_depth=max_depth\n",
        "        self.features=features\n",
        "        self.root=None\n",
        "\n",
        "    def infgain(self, y, xc, threshold):\n",
        "        parent_entropy = self.entropy(y)\n",
        "\n",
        "        l, r = self.split(xc, threshold)\n",
        "        if len(l) == 0 or len(r) == 0:\n",
        "            return 0\n",
        "\n",
        "        n_l=len(l)\n",
        "        n_r=len(r)\n",
        "        e_l=self.entropy(y[l])\n",
        "        e_r=self.entropy(y[r])\n",
        "        child_l=(n_l/len(y)) * e_l\n",
        "        child_r=(n_r/len(y)) * e_r\n",
        "        child_entropy =child_l+child_r\n",
        "\n",
        "        ig = parent_entropy - child_entropy\n",
        "        return ig\n",
        "\n",
        "    def entropy(self, y):\n",
        "        ricorrenze= np.bincount(y)\n",
        "        pp=ricorrenze / len(y)\n",
        "        return -np.sum([p * np.log(p) for p in pp if p>0])\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.features = x.shape[1] if not self.features else min(x.shape[1],self.features)\n",
        "        self.root = self.build(x, y)\n",
        "\n",
        "    def mc_label(self, y):\n",
        "        counter = Counter(y)\n",
        "        value = counter.most_common(1)[0][0]\n",
        "        return value\n",
        "\n",
        "    def build(self, x, y, depth=0):\n",
        "        n_samples, n_f = x.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        if (depth>=self.max_depth or n_labels==1 or n_samples<self.min_samples_split):\n",
        "            leaf_value =  self.mc_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        feature = np.random.choice(n_f, self.features, replace=False)\n",
        "\n",
        "        bfeature, bthresh = self.bestsplit(x, y, feature)\n",
        "\n",
        "        lefti, righti= self.split(x[:, bfeature], bthresh)\n",
        "        left = self.build(x[lefti, :], y[lefti], depth+1)\n",
        "        right = self.build(x[righti, :], y[righti], depth+1)\n",
        "        return Node(bfeature, bthresh, left, right)\n",
        "\n",
        "\n",
        "    def split(self, x_column, t):\n",
        "        left= np.argwhere(x_column <= t).flatten()\n",
        "        right= np.argwhere(x_column > t).flatten()\n",
        "        return left, right\n",
        "\n",
        "    def bestsplit(self, x, y, feature):\n",
        "        best_gain = -1\n",
        "        rsplit, rthreshold = None, None\n",
        "\n",
        "        for f in feature:\n",
        "            xc = x[:, f]\n",
        "            thresholds = np.unique(xc)\n",
        "\n",
        "            for t in thresholds:\n",
        "\n",
        "                gain = self.infgain(y, xc, t)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    rsplit = f\n",
        "                    rthreshold = t\n",
        "\n",
        "        return rsplit, rthreshold\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self.ttree(x, self.root) for x in X])\n",
        "\n",
        "    def ttree(self, x, node):\n",
        "        if node.is_leaf_node():\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self.ttree(x, node.left)\n",
        "        return self.ttree(x, node.right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npr8yQBdpUiK"
      },
      "outputs": [],
      "source": [
        "clf = DecisionTree(max_depth=10)\n",
        "clf.fit(x_train, y_train)\n",
        "predictions = clf.predict(x_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI7YZLimbQjo"
      },
      "source": [
        "valuto l'accuracy del mio decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrrGzXQMPo78"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy:\", accuracy(y_test, predictions)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaWutNN4nJ_K"
      },
      "source": [
        "confronto con sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfPXh8zNnIY7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "model = DecisionTreeClassifier(\n",
        "    criterion=\"entropy\"\n",
        ")\n",
        "\n",
        "model = model.fit(x_train,y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4Q6QyDonL2T"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-c_U5U1J7o"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFnrBwG21OQ5"
      },
      "source": [
        " **senza regolarizzazione**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wziS09eLCXMg"
      },
      "source": [
        "realizzo il mylinearRegression senza regolarizzazione usando gradient descent.\n",
        "\n",
        "\n",
        "* __init__(): contine il tasso di apprendimento, il numero di iterazioni oltre che ai pesi (weights) e al bias (w0). Si potrebbe inoltre inserire un elenco che memorizza il Loss, utlie se si volesse vedere la curva di apprendimento.\n",
        "*   mse(): uso l'errore quadratico medio come funzione di costo da minimizzare e rappresenta l'errore. Con y i valori veri che mi aspetto e y_h i valori che ho trovato (predetto).\n",
        "*  fit(): funzione che cerca di ottimizzare i valori dei pesi e del bias usando gradiant descnt, per prima cosa imposto il peso e il bias a 0.\n",
        "Poi comincio ad usare il gradient descent e calcolo le derivate e aggiorno il peso e il bias\n",
        "*   predict() funzione che predice usando quazioni lineari\n",
        "\n",
        "Nel caso decidessi di memorizzare Loss=[ ] sarebbe una lista che memorizza i valori di loss durante la fase di addestramento e può essere utilizzata per analizzare il comportamento del modello\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb6pwtu8ElNy"
      },
      "outputs": [],
      "source": [
        "class myLinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, iterations=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations=iterations\n",
        "        self.w=None\n",
        "        self.b=None\n",
        "\n",
        "    @staticmethod\n",
        "    def mse(y, y_h):\n",
        "        error = 0\n",
        "        for i in range(len(y)):\n",
        "            diff=y[i]-y_h[i]\n",
        "            error += (diff) ** 2\n",
        "        return error / len(y)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "\n",
        "        self.w= np.zeros(x.shape[1])\n",
        "        self.b= 0\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "\n",
        "            y_h= np.dot(x, self.w) + self.b\n",
        "\n",
        "\n",
        "            partial_w = (1 / x.shape[0]) * (2 * np.dot(x.T, (y_h - y)))\n",
        "            partial_d = (1 / x.shape[0]) * (2 * np.sum(y_h - y))\n",
        "\n",
        "            self.w-= self.learning_rate * partial_w\n",
        "            self.b-= self.learning_rate * partial_d\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.w) + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1u2zg8GE4Zy"
      },
      "source": [
        "Uso strain_test_split come nel caso degli alberi di decisione ma ora la y contiene la penultima colonna e non la colonna dei True e False\n",
        "\n",
        "**uso quasi sempre la normalizzazione sui dati poichè non facendolo avevo spesso errori dovuti a overflow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYUqt4Go1Vod"
      },
      "outputs": [],
      "source": [
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -2].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x1, y, test_size=0.2, random_state=1234)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdD7TzCp5eZ8"
      },
      "outputs": [],
      "source": [
        "model = myLinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "preds = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HvyNF6NMXO3"
      },
      "source": [
        "calcolo RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks9PaLA8CNlb"
      },
      "outputs": [],
      "source": [
        "rmse(y_test, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da2hP4SOMobh"
      },
      "source": [
        "confronto con LinearRegression di sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAHuYOUtx4Fn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(x_train, y_train)\n",
        "lr_preds = lr_model.predict(x_test)\n",
        "print(math.sqrt(mean_squared_error(y_test, lr_preds)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW5CHl69uNqX"
      },
      "source": [
        "**Con regolarizzazione L1, L2 e Elastic Net**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMs9bp66A_QT"
      },
      "source": [
        "In questo codice uso la regolarizzazione utile per evitare overfitting.\n",
        "Il codice è molto simile a quello precendete senza regolarizzazione.\n",
        "La mia funzione di costo da minimizzare non sarà solo data da EmpLoss ovvero mse ma anche da una termine che mi misura la complessità del mio modello, la somma tra questi due valori mi darà il costo.\n",
        "\n",
        "$$ Cost(h)= EmpLoss(h) + λComplexity(h) $$\n",
        "\n",
        "Uso una regolarizzazione L1, L2 e Elastic Net.\n",
        "Con L1 la complessità sarà la somma in modulo dei pesi:\n",
        "\n",
        "$$\n",
        "\\sum\\limits_{i=1}^{n}{\\Big|w_i\\Big|}\n",
        "$$\n",
        "\n",
        "con L2 sarà la somma dei quadrati dei pesi:\n",
        "\n",
        "$$\n",
        "\\sum\\limits_{i=1}^{n}{\\Big|w_i\\Big|^2}\n",
        "$$\n",
        "\n",
        "con Elastic Net è la combinazione di L1 e L2\n",
        "\n",
        "$$ λ_1L_1(w) + λ_2L_2(w) $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH7mdUjdIhvu"
      },
      "outputs": [],
      "source": [
        "class myRLinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, iterations=1000, regular=\"None\",lamb=1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations=iterations\n",
        "        self.w=None\n",
        "        self.b=None\n",
        "        self.loss = []\n",
        "        self.lamb=lamb\n",
        "        self.regular=regular\n",
        "\n",
        "    @staticmethod\n",
        "    def costo(y, y_h, self):\n",
        "        error = 0\n",
        "        for i in range(len(y)):\n",
        "            diff=y[i]-y_h[i]\n",
        "            error += (diff) ** 2\n",
        "        mse=error/len(y)\n",
        "        if(self.regular==\"L1\" or self.regular==\"None\" ):\n",
        "          compl=np.sum(np.abs(self.w))*self.lamb\n",
        "        if(self.regular==\"L2\"):\n",
        "          compl=np.sum(self.w**2)*self.lamb\n",
        "        if(self.regular==\"EN\"):\n",
        "          a=self.lamb/(self.lamb+self.lamb)\n",
        "          compl=np.sum(np.abs(self.w))*a\n",
        "          compl+=np.sum(self.w**2)*(1-a)\n",
        "        return mse+compl\n",
        "\n",
        "    def fit(self, x, y):\n",
        "\n",
        "        self.w= np.zeros(x.shape[1])\n",
        "        self.b= 0\n",
        "\n",
        "        for i in range(self.iterations):\n",
        "\n",
        "            y_h= np.dot(x, self.w) + self.b\n",
        "            loss = self.costo(y, y_h, self)\n",
        "            self.loss.append(loss)\n",
        "\n",
        "            if self.regular == \"L1\" or self.regular is None:\n",
        "                reg = np.sign(self.w) * self.lamb\n",
        "            elif self.regular == \"L2\":\n",
        "                reg = 2 * self.w * self.lamb\n",
        "            elif self.regular == \"EN\":\n",
        "                a = self.lamb / (self.lamb + self.lamb)\n",
        "                reg = a * np.sign(self.w) + (1 - a) * 2 * self.w\n",
        "\n",
        "            partial_w = ((1 / x.shape[0]) * (2 * np.dot(x.T, (y_h - y)))) + reg\n",
        "            partial_d = (1 / x.shape[0]) * (2 * np.sum(y_h - y))\n",
        "\n",
        "            self.w -= self.learning_rate * partial_w\n",
        "            self.b -= self.learning_rate * partial_d\n",
        "\n",
        "    def predict(self, x):\n",
        "        return np.dot(x, self.w) + self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UgGtFuujDF-4"
      },
      "outputs": [],
      "source": [
        "model2=myRLinearRegression(regular=\"L2\",lamb=0.001)\n",
        "model2.fit(x_train, y_train)\n",
        "preds2 = model2.predict(x_test)\n",
        "model1=myRLinearRegression(regular=\"L1\",lamb=0.00000001)\n",
        "model1.fit(x_train, y_train)\n",
        "preds1 = model1.predict(x_test)\n",
        "model3=myRLinearRegression(regular=\"EN\",lamb=0.01)\n",
        "model3.fit(x_train, y_train)\n",
        "preds3 = model3.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JCX0zkXgltnO"
      },
      "outputs": [],
      "source": [
        "def rmse(y, y_h):\n",
        "        error = 0\n",
        "        for i in range(len(y)):\n",
        "            diff=y[i]-y_h[i]\n",
        "            error += (diff) ** 2\n",
        "        return math.sqrt(error / len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2Y9b_IEGMv1c",
        "outputId": "2222897a-e4c2-4aa7-b2f3-f71664037e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmse di L1: 7644.357472278812\n",
            "rmse di L2: 7644.373647415458\n",
            "rmse di EN: 7662.048284406315\n",
            "rmse senza regolarizzazione: 7664.190902971467\n"
          ]
        }
      ],
      "source": [
        "print(\"rmse di L1:\", rmse(y_test, preds1))\n",
        "\n",
        "print(\"rmse di L2:\", rmse(y_test, preds2))\n",
        "\n",
        "print(\"rmse di EN:\", rmse(y_test, preds3))\n",
        "\n",
        "print(\"rmse senza regolarizzazione:\",rmse(y_test, preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdtSOhK5Xcix"
      },
      "source": [
        "Uso sklearn per fare un paragone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8BYLJbrxXgbr",
        "outputId": "948c2bf6-6f37-4cb7-fe23-d8f70992a927"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.381e+12, tolerance: 4.877e+08\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np\n",
        "\n",
        "lasso_reg = Lasso(alpha=0.001)\n",
        "lasso_reg.fit(x_train, y_train)\n",
        "y_pred1 = lasso_reg.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pyg9YdGgX7iN"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge(alpha=0.001)\n",
        "ridge_reg.fit(x_train, y_train)\n",
        "y_pred2 = ridge_reg.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2TOHi_oKYKf8",
        "outputId": "6597874b-c370-4076-8cb0-a48871e0d899"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.328e+12, tolerance: 4.877e+08\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "elastic_net = ElasticNet(alpha=0.01, l1_ratio=1)\n",
        "elastic_net.fit(x_train, y_train)\n",
        "y_pred3 = elastic_net.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nBBYdqcuYZfG",
        "outputId": "781750eb-2207-4bb4-d7c8-7203df59f4c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmse di L1 (sklearn): 7644.7966167862905\n",
            "rmse di L2 (sklearn): 7643.521846630049\n",
            "rmse di EN (sklearn): 7644.799860437362\n",
            "rmse senza regolarizzazione (sklearn) : 7643.5016967501315\n"
          ]
        }
      ],
      "source": [
        "print(\"rmse di L1 (sklearn):\", rmse(y_test, y_pred1))\n",
        "\n",
        "print(\"rmse di L2 (sklearn):\", rmse(y_test, y_pred2))\n",
        "\n",
        "print(\"rmse di EN (sklearn):\", rmse(y_test, y_pred3))\n",
        "\n",
        "print(\"rmse senza regolarizzazione (sklearn) :\",rmse(y_test, lr_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuRF1fApmLKN"
      },
      "source": [
        "# Linear Classification as Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcfJBgJRK9q6"
      },
      "source": [
        "l'ultima colonna continete shares che è il valore da predirre. Separiamo le feature dal target e per comodità uso per le y la colonna che ho aggiunto che ha valori True e False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RecsOUuaKcNP"
      },
      "outputs": [],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth\n",
        "\n",
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y, test_size=0.2, random_state=1234\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s2oZkrlzgOu"
      },
      "source": [
        "Nel caso di classificazione usiamo la Perceptron che utilizza la classificazione binaria. L'algoritmo si addestra iterativamente con i dati di addestramento e aggiornare i pesi e il bias.\n",
        "\n",
        "\n",
        "* __init__(): inizializza l'oggetto impostando w (peso) e b (bias) a None e i parametri learning_rate e iterazioni\n",
        "* fit(): addestra il Perceptron sui dati x. Con x.shape salvo il numero di samples e di features.\n",
        "Inizializzo w e b a 0.\n",
        "yy è una \"copia\" di y in un formato binario usando np.where (se necessario).\n",
        "Poi attraverso i cicli va ad aggiornare i pesi e il bias e usando la funzione di Threshold vista a lezione in cui h(x)=1 se >=0 altrimenti è 0.\n",
        "Da questa  aggiorno:\n",
        "$$w=w+learning_rate*(yy[id]-h(x))*xi$$ a cui ho aggiunto il bias per averre un accuracy migliore.\n",
        "* predict(): utilizza il Perceptron addestrato in precedenza con la funzione fit() per classificare nuovi esempi x.\n",
        "* funzione() è la funzione a gradino che restituisce 1 se l'input è >=0 altrimenti restituisce 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WCAszeI9Spot"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, iterazioni=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterazioni=iterazioni\n",
        "        self.w=None\n",
        "        self.b=None\n",
        "\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        n_samples, n_features = x.shape\n",
        "        self.w=np.zeros(n_features)\n",
        "        self.b=0\n",
        "\n",
        "        yy= np.where(y > 0 , 1, 0)\n",
        "\n",
        "        for _ in range(self.iterazioni):\n",
        "            for id, xi in enumerate(x):\n",
        "                lout = np.dot(xi, self.w) + self.b\n",
        "                y_p=self.funzione(lout)\n",
        "\n",
        "                u=self.learning_rate * (yy[id] - y_p)\n",
        "                self.w+= u*xi\n",
        "                self.b+= u\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        lout = np.dot(x, self.w) + self.b\n",
        "        y_p= self.funzione(lout)\n",
        "        print(y_p)\n",
        "        return y_p\n",
        "\n",
        "    def funzione(self, x):\n",
        "        return np.where(x >= 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7zGNkoRDwGLX",
        "outputId": "8b3e05d8-5f3a-4a28-9586-5aa2078f46b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 1 ... 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "p = Perceptron(learning_rate=0.01, iterazioni=1000)\n",
        "p.fit(x_train, y_train)\n",
        "predictions = p.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LRUQRmiYEJQ"
      },
      "source": [
        "definisco accuracy e stampo il risultato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cLAx94uxQOW3"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Nto6OAxHQQF6",
        "outputId": "c64b7342-7edf-4c8e-cd93-f97c847150d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55.55555555555556\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(y_test, predictions)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boQst5zOZJ0O"
      },
      "source": [
        "Uso sklearn per verificare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iMICVlrWZQgm"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "perceptron = Perceptron()\n",
        "perceptron.fit(x_train, y_train)\n",
        "pperceptron = perceptron.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HdmYi3qXZYsN",
        "outputId": "5277750f-d6f1-459d-97bf-f9723bfc7024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55.56816748644218\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(y_test, pperceptron)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTAfW3efQHdX"
      },
      "source": [
        "# Classificazione con regressione logistica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25xPB6m9cW7e"
      },
      "source": [
        "implemento un modello di regressione logistica che è un algoritmo di apprendimento automatico per la classificazione binaria. L'algoritmo utilizza una funzione sigmoide per calcolare la probabilità che un campione appartenga alla classe positiva, e  utilizza il metodo del gradient descent per minimizzare la funzione di perdita e per aggioranre i valore di peso (w) e bias (b).\n",
        "\n",
        "* __init__(): è il costruttore della classe:\n",
        "    1. learning_rate rappresenta il tasso di apprendimento per l'algoritmo di discesa del gradiente.\n",
        "    2. iterazioni rappresenta il numero di iterazioni da eseguire\n",
        "    3. w e b sono rispettivamente i pesi e il bias che verranno aggiornati durante l'addestramento.\n",
        "\n",
        "* sigmoid(): funzione sigmoide utilizzata per trasformare la somma pesata degli input in una probabilità tra 0 e 1:\n",
        "              \n",
        "$$\\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "            \n",
        "\n",
        "*   BCE():calcola la funzione di costo della regressione logistica, ovvero la binary cross-entropy loss:\n",
        "$$-(y*log(h))+(1-y)*log(1-h))$$\n",
        "\n",
        "*   fit(): metodo principale che allena il modello usando i dati di x.\n",
        "inizializza i parametri w e b, poi ottimizza in modo iterativo pesi e bias attraverso gradient descent, calcola le derivate e aggiorna w e b\n",
        "* pprob() calcola le probabilità di appartenenza alla classe positiva utilizzando le equazioni lineare passate alla funzione  sigmoidea\n",
        "* predict() esegue la previsione sui dati di input\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bCCzIWY81nt0"
      },
      "outputs": [],
      "source": [
        "class myLogisticRegression:\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, iterazioni=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterazioni=iterazioni\n",
        "        self.w=None\n",
        "        self.b=None\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def BCE(self, y, h):\n",
        "        t= 0\n",
        "        for yy, hh in zip(y, h):\n",
        "            t += (yy * np.log(hh)) + (1 - yy) *np.log(1-hh)\n",
        "        return - t / len(y)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "\n",
        "        self.w = np.zeros(x.shape[1])\n",
        "        self.b = 0\n",
        "\n",
        "        for i in range(self.iterazioni):\n",
        "            lp = np.dot(x, self.w) + self.b\n",
        "            h = self.sigmoid(lp)\n",
        "\n",
        "\n",
        "            pw = (1 / x.shape[0]) * (np.dot(x.T, (h - y)))\n",
        "            pd = (1 / x.shape[0]) * (np.sum(h - y))\n",
        "\n",
        "\n",
        "            self.w -= self.learning_rate * pw\n",
        "            self.b -= self.learning_rate * pd\n",
        "\n",
        "    def pprob(self, x):\n",
        "        pred=np.dot(x, self.w) + self.b\n",
        "        return self.sigmoid(pred)\n",
        "\n",
        "    def predict(self, x, threshold=0.5):\n",
        "        probab=self.pprob(x)\n",
        "        return [1 if i > threshold else 0 for i in probab]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXbbASAbcXyT"
      },
      "source": [
        "ho normalizzato i dati per evitare problemi con il calcolo del sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Y-7hG6UIlVxA"
      },
      "outputs": [],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth\n",
        "\n",
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y, test_size=0.2, random_state=1234\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xfs9HDLMcYPN"
      },
      "outputs": [],
      "source": [
        "model = myLogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "predsss = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AKUYKyG8BWx"
      },
      "source": [
        "calcolo l'accuratezza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d4s9w6T9lsHd",
        "outputId": "adaa59dc-bc13-4df7-96f6-443d03a46db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64.77487703367385\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(y_test, predsss)*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stfo6Sf2Zqi_"
      },
      "source": [
        "faccio un confronto con sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Fu6WsQm31iO9",
        "outputId": "26215ba6-e2d6-43ee-c454-617c13085562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65.30457813091184\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(x_train, y_train)\n",
        "lr_preds = lr_model.predict(x_test)\n",
        "\n",
        "print(accuracy(y_test, lr_preds)*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elD3uZ2oclHj"
      },
      "source": [
        "# Classificazione con algoritmo di k-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixLGnmLwtRz9"
      },
      "source": [
        "K-Nearest Neighbors (KNN) non richiede apprendimento, ma calcola semplicemente la distanza, in questo caso usando la distanza euclidea. Si basa sul principio che gli oggetti con caratteristiche simili tendono ad essere vicini l'uno all'altro nello spazio delle caratteristiche. Per assegnare un determinato output vedo l'etichetta più comune tra i k vicini e assegno quella all'output dei miei dati di test.\n",
        "Anche in questo caso ho normalizzato i dati x.\n",
        "\n",
        "\n",
        "* __init__(k): memorizza il nuemro di vicini (k), ho impostato come valore predefinito k=5.\n",
        "* disteuclidea(): è la funzione che calcola la distanza euclidea tra i punti p e q:\n",
        "\n",
        "$$ \\sqrt{\\sum\\limits_{i=1}^{n}{\\Big(p_i -q_i\\Big)^2}} $$\n",
        "\n",
        "* fit(): prende in input dei dati x e dei target y e li memorizza in xt e yt\n",
        "* predict(): per ogni dato in x calcola la distanza euclidea tra tale punto e tutti i punti in xt. Poi seleziona i k punti (dei xt) con la distanza euclidea minore e usa i loro target (contenuti in yt) per determinare il valore di output del valore del dato di x in esame.\n",
        "Usando np.bincount conta il numero di occorrenze e restituisce il valore più comune.\n",
        "Tutte le predizioni vengono restituite come un array\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D7ItSCGZkg55"
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "\n",
        "    def disteuclidea(self, p, q):\n",
        "        return np.sqrt(np.sum((p - q) ** 2))\n",
        "\n",
        "    def fit(self, x, y):\n",
        "\n",
        "        self.xt = x\n",
        "        self.yt = y\n",
        "\n",
        "    def predict(self, x):\n",
        "        predictions = []\n",
        "        for i in x:\n",
        "            d= [self.disteuclidea(i, q) for q in self.xt]\n",
        "            indicivicini = np.argsort(d)[:self.k]\n",
        "            valorivicini = self.yt[indicivicini]\n",
        "            mcomune= np.bincount(valorivicini).argmax()\n",
        "            predictions.append(mcomune)\n",
        "\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WPg7boWzqCED"
      },
      "outputs": [],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth\n",
        "\n",
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y, test_size=0.2, random_state=1234\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ipn7CncCp7Gk"
      },
      "outputs": [],
      "source": [
        "model = KNN()\n",
        "model.fit(x_train, y_train)\n",
        "preds = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnbq1U8mz25O"
      },
      "source": [
        "vedo l'accuratezza del mio risultato con k=5. Sarebbe possibile provarla con altri valori di k (preferibbilmente dispari) in modo da trovare il valore di k che mi restituisce un accuracy migliore. Nel mio caso uso k=5 che comunque mi restituisce un valore buono"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EQxAIMIQqN4p",
        "outputId": "b7884dd1-fc9c-4b8e-e828-0ce040d70850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "61.268760247193846\n"
          ]
        }
      ],
      "source": [
        "print(accuracy(y_test, preds)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sra-zrQG1d26"
      },
      "source": [
        "uso sklearn per verificare se il mio codice funziona. In questo caso faccio usare diversi valori di k per vedere come possono cambiare i risultati. Con k=5 i risultati sono simili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tDDIoH-s0Or5",
        "outputId": "cc972d92-fca9-49e1-c1b6-2282b6c718c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy con k= 1 57.44734518854837\n",
            "accuracy con k= 3 59.64182116282003\n",
            "accuracy con k= 5 61.268760247193846\n",
            "accuracy con k= 7 61.609282381132545\n",
            "accuracy con k= 9 61.55883465758608\n",
            "accuracy con k= 11 62.34077437255644\n",
            "accuracy con k= 13 62.47950561230925\n",
            "accuracy con k= 15 63.32450498171271\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "for k in range(1, 16, 2):\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(x_train, y_train)\n",
        "    knn_preds = knn_model.predict(x_test)\n",
        "    print(\"accuracy con k=\", k,accuracy(y_test, knn_preds)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDlj_YMQ2Ine"
      },
      "source": [
        "# Regressione con algoritmo di k-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg1LwP6W2Pi-"
      },
      "source": [
        "identico al precedente solo che invece che considerare il valore più presente dei vicini, faccio una media dei valori vicini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mfJHbNj92PEr"
      },
      "outputs": [],
      "source": [
        "class KNNR:\n",
        "    def __init__(self, k=5):\n",
        "        self.k = k\n",
        "\n",
        "    def disteuclidea(self, p, q):\n",
        "        return np.sqrt(np.sum((p - q) ** 2))\n",
        "\n",
        "    def fit(self, x, y):\n",
        "\n",
        "        self.xt = x\n",
        "        self.yt = y\n",
        "\n",
        "    def predict(self, x):\n",
        "        predictions = []\n",
        "        for i in x:\n",
        "            d= [self.disteuclidea(i, q) for q in self.xt]\n",
        "            indicivicini = np.argsort(d)[:self.k]\n",
        "            valorivicini = self.yt[indicivicini]\n",
        "            predictions.append(np.mean(valorivicini))\n",
        "\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BmemsbUPVjbG"
      },
      "outputs": [],
      "source": [
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -2].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y, test_size=0.2, random_state=1234\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYAw_PdYeYOK"
      },
      "source": [
        "Vado a testare la mia funzione KNNR e la valuto calcolando rmse. Anche in questo caso io uso K=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gWqOw9H-V7pM"
      },
      "outputs": [],
      "source": [
        "modelr = KNNR()\n",
        "modelr.fit(x_train, y_train)\n",
        "predsr = modelr.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X97Id79jWthP",
        "outputId": "489e9e34-3721-46c5-bb43-538ee41e78df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8863.510513824622\n"
          ]
        }
      ],
      "source": [
        "print(rmse(y_test,predsr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLcA7j0gejxn"
      },
      "source": [
        "uso la funzione sklearn per calcolare k-Nearest Neighbors provando con diversi valori di k e valutandoli calcolando il rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HbYJ7_Z7W7qK",
        "outputId": "c1b2da94-6add-44ce-8139-2015281b96cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rmse con k= 1 14204.880563442526\n",
            "rmse con k= 3 9627.502493220327\n",
            "rmse con k= 5 8863.510513824622\n",
            "rmse con k= 7 8638.310439798033\n",
            "rmse con k= 9 8482.943213405948\n",
            "rmse con k= 11 8302.237780878917\n",
            "rmse con k= 13 8206.197354323005\n",
            "rmse con k= 15 8098.8119796431465\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "for k in range(1, 16, 2):\n",
        "    knnr_model = KNeighborsRegressor(n_neighbors=k)\n",
        "    knnr_model.fit(x_train, y_train)\n",
        "    knnr_preds = knnr_model.predict(x_test)\n",
        "    print(\"rmse con k=\", k,rmse(y_test, knnr_preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--IfXnLpcnql"
      },
      "source": [
        "#Regressione con Reti Neurali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2hz08Madsjg"
      },
      "source": [
        "Realizzo una rete neurale per la regressioe a tre strati: un input layer, un hidden layer e un output layer in cui posso variare il numero di elementi nel hiddenn layer.\n",
        "* __init__(): è il costruttore che prende in input i_s (input size), hs (hidden size) e os (output size), che rappresentano rispettivamente il numero di neuroni nell'input layer, nel hidden layer e nell'output layer. Inizializzo casualmente i pesi e il bias tra lo strato di input e lo strato nascosto wh1 e bh1 e i   pesi e il bias tra lo strato nascosto e lo strato di output wo2 e bo2.\n",
        "* relu()  implementa la funzione di attivazione ReLU:\n",
        "$$max(0,x)$$\n",
        "\n",
        "* relu_deriv() la derivata della funzione relu\n",
        "* mse(): La funzione di costo utilizzata è il Mean Squared Error (MSE):\n",
        "\n",
        "\n",
        "$$\n",
        "\\frac{1}{n}\\sum\\limits_{i=1}^{n}{\\Big(d_i -f_i\\Big)^2}\n",
        "$$\n",
        "\n",
        "* mse_deriv() la derivata della funzione costo rispetto all'output del modello\n",
        "\n",
        "* forward():implementa il forward pass, è responsabile di eseguire il passaggio in avanti della rete neurale. Riceve in input i dati di input x e calcola l'output predetto y_hat.\n",
        "Inizia calcolando l'uscita del hidden layer (l1) e poi applico la funzione di attivazione relu e la salvo in a1 che sarà l'input del layer output.\n",
        "Calcolo in fine l'output (y_hat) in maniera  lineare (moltiplicando l'attivazione dell'hidden layer a1 con i pesi dell'output layer wo2, cui viene sommato il bias dell'output layer bo2)\n",
        "\n",
        "* backward(): implementa il backpropagation, calcola la retropropagazione dell'errore attraverso la rete neurale e aggiorna i pesi dei suoi parametri in base all'errore calcolato. Dopo la fase di  forward pass si procede con il backpropagation:\n",
        "    1. Per prima cosa si calcola la derivata parziale dell'errore rispetto all'output usando la funzione di costo (in questo caso MSE).\n",
        "Viene poi calcolato il gradiente dell'errore rispetto al secondo layer (quello che collega hidden a output). In fine si calcolano le derivate parziali per wo2 e bo2\n",
        "    2. Viene calcolato il gradiente dell'errore rispetto all'hidden layer usando la derivata della funzione di attivazione ReLu (relu_deriv()) e salvato in l1_deriv. In fine si calcolano le derivate parziali per wh1 e bh1.\n",
        "\n",
        "    3. alla fine vengono aggioranti i pesi e il bias usando il gradiant descent\n",
        "  \n",
        "* fit(): viene addestrata la rete neurale attraverso un loop di epochs epoche. Ad ogni loop eseguo forward propagation e poi backward propagation dove si aggiornano i pesi e il bias.\n",
        "Ho messo una stampa ogni 500 epoche per vedere come scnedeva la loss.\n",
        "\n",
        "* predict(): prendice il risultato dei dati di input x.\n",
        "\n",
        "Ho usato y = y.reshape(-1, 1) perchè spesso avevo problemi di dimensioni.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xUaj7uAefKrw"
      },
      "outputs": [],
      "source": [
        "class NNR:\n",
        "    def __init__(self, i_s, hs, os):\n",
        "        self.wh1 = np.random.randn(i_s, hs) - 0.5\n",
        "        self.bh1 = np.zeros((1, hs)) - 0.5\n",
        "        self.wo2 = np.random.randn(hs, os) - 0.5\n",
        "        self.bo2 = np.zeros((1, os)) - 0.5\n",
        "\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def relu_deriv(self, a):\n",
        "        return np.where(a > 0, 1, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.l1 = np.dot(x, self.wh1) + self.bh1\n",
        "        self.a1 = self.relu(self.l1)\n",
        "        self.l2 = np.dot(self.a1, self.wo2) + self.bo2\n",
        "        self.y_hat = self.l2\n",
        "\n",
        "    def mse(self, y, y_hat):\n",
        "        return np.mean(np.square(y - y_hat))\n",
        "\n",
        "    def mse_deriv(self, y, y_hat):\n",
        "        return (y_hat - y)\n",
        "\n",
        "    def backward(self, x, y, lr):\n",
        "        y = y.reshape(-1, 1)\n",
        "\n",
        "        mse_deriv = self.mse_deriv(y, self.y_hat)\n",
        "        l2_deriv = mse_deriv\n",
        "        wo2_deriv = np.dot(self.a1.T, l2_deriv)\n",
        "        bo2_deriv = np.sum(l2_deriv, axis=0, keepdims=True)\n",
        "\n",
        "        a1_deriv = np.dot(l2_deriv, self.wo2.T)\n",
        "        l1_deriv = a1_deriv * self.relu_deriv(self.l1)\n",
        "        wh1_deriv = np.dot(x.T, l1_deriv)\n",
        "        bh1_deriv = np.sum(l1_deriv, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "        self.wh1 -= lr * wh1_deriv\n",
        "        self.bh1 -= lr * bh1_deriv\n",
        "        self.wo2 -= lr * wo2_deriv\n",
        "        self.bo2 -= lr * bo2_deriv\n",
        "\n",
        "    def train(self, x, y, epochs, lr):\n",
        "        for i in range(epochs):\n",
        "            y = y.reshape(-1, 1)\n",
        "            self.forward(x)\n",
        "            loss = self.mse(y, self.y_hat)\n",
        "            self.backward(x, y, lr)\n",
        "            if i % 500 == 0:\n",
        "                print(f\"Epoch {i}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.forward(x)\n",
        "        return self.y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S7KxtPOqzJx"
      },
      "source": [
        "\n",
        "definisco i dati **solo in questo caso ho deciso di normalizzare anche le y invce che solo le x. questo perchè con dati y cosi grandi avevo numerosi problemi tra cui quelli di overflow**\n",
        "\n",
        "\n",
        "**N.B il problema è stato testato anche con y non normalizzate, funziona comunque ma con risultati spesso non ottimali**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bqvDqXg8qIlK"
      },
      "outputs": [],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth\n",
        "\n",
        "x = df.iloc[: , :-2].values\n",
        "y = df.iloc[: , -2].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)+ 1e-8\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "meany = np.mean(y, axis=0)\n",
        "stdy = np.std(y, axis=0)+ 1e-8\n",
        "\n",
        "y1 = (y - meany) / stdy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y1, test_size=0.2, random_state=1234\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1mJQjrkq37A"
      },
      "source": [
        "alleno la mia funzione e faccio la predizione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tsu1eWUGqOLN",
        "outputId": "e308e4ec-6196-4159-bcc2-3e7cc450465e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 360.3203\n",
            "Epoch 500, Loss: 1.1424\n",
            "Epoch 1000, Loss: 1.1370\n",
            "Epoch 1500, Loss: 1.1354\n",
            "Epoch 2000, Loss: 1.1350\n",
            "Epoch 2500, Loss: 1.1348\n",
            "Epoch 3000, Loss: 1.1348\n",
            "Epoch 3500, Loss: 1.1348\n",
            "Epoch 4000, Loss: 1.1347\n",
            "Epoch 4500, Loss: 1.1347\n"
          ]
        }
      ],
      "source": [
        "nett = NNR(x_train.shape[1], 6, 1)\n",
        "nett.train(x_train, y_train, lr=0.0000001, epochs=5000)\n",
        "predizioner = nett.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luHEcaSXrL4v"
      },
      "source": [
        "rmse sulla mia predizione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NHle1ErPAAVX",
        "outputId": "e401533a-e023-4353-be17-638df39462b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6689832975219531\n"
          ]
        }
      ],
      "source": [
        "print(rmse(y_test,predizioner))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itVFxb39rNEs"
      },
      "source": [
        "faccio un paragone usando sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yf5hNCDIG9rp",
        "outputId": "7a237afe-3764-4fca-b0ef-152bf16dbc87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6619178919912933\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "\n",
        "modelr = MLPRegressor(4, activation='relu', max_iter=5000)\n",
        "modelr.fit(x_train, y_train)\n",
        "y_predrr = modelr.predict(x_test)\n",
        "print(rmse(y_test,y_predrr))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1OaXxSmcrZZ"
      },
      "source": [
        "# Classificazione con Reti Neurali"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgp-RMLZrPfS"
      },
      "source": [
        "Molto simile a quella realizzata precedentemente per la regressione, è un codice per la classificazione binaria, dove l'output può assumere solo due valori: 0 o 1.\n",
        "La rete neurale ha un singolo strato nascosto e utilizza la funzione di attivazione ReLU per il primo strato e la funzione di attivazione sigmoide per l'output.\n",
        "\n",
        "* __init__(): identico al precendete dove inizializzo randomicamnete wh1, wo2, bh1 e bo2.\n",
        "\n",
        "* __relu()__ e relu_derivative(): come nel caso precedente\n",
        "\n",
        "* sigmoid(): implementano la funzione di attivazione sigmoide:\n",
        "$$\\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "* sigmoid_derivative(): calcola la derivata della sigmoide:\n",
        "$$ sigmoid(x)(1 - sigmoid(x)) $$\n",
        "\n",
        "* forward() come prima implementa il Forward Pass calcolando l'output y_h.\n",
        "Per prima cosa calcolo l1 e poi vine passto alla funzione relu che applica quindi la funzione di attivazione ReLu e restituisce a1.\n",
        "a1 sarebbe l'input per la parte successiva per il calcolo di l2. l2 viene poi passato alla funzione di attivazione sigmoide e restituisce y_h\n",
        "\n",
        "* backward():  implementa il passaggio all'indietro della rete neurale come nella NNR.\n",
        "\n",
        "    1. Viene calcolato l'errore dell'ultimo strato, ovvero la differenza tra l'output predetto y_hat e l'etichetta y, moltiplicata per la derivata della funzione di attivazione sigmoid_derivative() applicata all'ultimo strato self.l2. Viene poi calcolato il gradiente per wo2 e bo2.\n",
        "\n",
        "    2. Viene calcolato l'errore del livello nascosto, utilizzando il prodotto tra l'errore dell'ultimo strato errout e la matrice dei pesi dell'ultimo strato self.wo2 trasposta, moltiplicato per la derivata della funzione di attivazione relu_derivative() applicata al livello nascosto self.l1. Viene poi calcolato il gradiente per wh1 e bo1\n",
        "\n",
        "    3. Vengono aggiornati i pesi e i bias\n",
        "\n",
        "\n",
        "* fit(): esegue il processo di addestramento della rete neurale per il numero specificato di epoche, stampando l'errore di addestramento ogni 100 epoche.\n",
        "\n",
        "* predict():  prende in input un insieme di dati di test e restituisce l'output. L'output viene arrotondato alla classe più probabile (0 o 1) utilizzando la funzione np.round().\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ce5vrDssRkqy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NNC:\n",
        "    def __init__(self, i_s, hs, os):\n",
        "        self.wh1 = np.random.rand(i_s, hs) - 0.5\n",
        "        self.bh1 = np.random.rand(1, hs) - 0.5\n",
        "        self.wo2 = np.random.rand(hs, os) - 0.5\n",
        "        self.bo2 = np.random.rand(1, os) - 0.5\n",
        "\n",
        "\n",
        "    def relu(self, a):\n",
        "        return np.maximum(0, a)\n",
        "\n",
        "    def relu_derivative(self, a):\n",
        "        return np.where(a > 0, 1, 0)\n",
        "\n",
        "    def sigmoid(self, a):\n",
        "        return 1 / (1 + np.exp(-a)/10000)\n",
        "\n",
        "\n",
        "    def sigmoid_derivative(self, a):\n",
        "        return self.sigmoid(a) * (1 - self.sigmoid(a))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.l1 = np.dot(x, self.wh1) + self.bh1\n",
        "        self.a1 = self.relu(self.l1)\n",
        "        self.l2 = np.dot(self.a1, self.wo2) + self.bo2\n",
        "        y_h = self.sigmoid(self.l2)\n",
        "\n",
        "        return y_h\n",
        "\n",
        "    def backward(self, x, y, y_hat, lr):\n",
        "        y = y.reshape(-1, 1)\n",
        "        errout = (y_hat - y) * self.sigmoid_derivative(self.l2)\n",
        "        dw2 = np.dot(self.a1.T, errout)\n",
        "        db2 = np.sum(errout, axis=0, keepdims=True)\n",
        "\n",
        "        errhide = np.dot(errout, self.wo2.T) * self.relu_derivative(self.l1)\n",
        "        dw1 = np.dot(x.T, errhide)\n",
        "        db1 = np.sum(errhide, axis=0, keepdims=True)\n",
        "\n",
        "        self.wh1 -= lr * dw1\n",
        "        self.bh1 -= lr * db1\n",
        "        self.wo2 -= lr * dw2\n",
        "        self.bo2 -= lr * db2\n",
        "\n",
        "    def fit(self, x, y, lr=0.1, epochs=1000):\n",
        "        for i in range(epochs):\n",
        "            y_h = self.forward(x)\n",
        "\n",
        "            self.backward(x, y, y_h, lr)\n",
        "\n",
        "            y = y.reshape(-1, 1)\n",
        "\n",
        "            costo = np.mean(np.square(y_h - y))\n",
        "            if i % 500 == 0:\n",
        "                print(f\"Epoch {i} - Loss: {costo}\")\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_h = self.forward(X)\n",
        "        a=np.round(y_h)\n",
        "        return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9ge5aGjyy5q"
      },
      "source": [
        "preparo i dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zjicb_QgkiI3"
      },
      "outputs": [],
      "source": [
        "df['higth'] = np.where(df['shares']>=1400, True, False)\n",
        "df.higth\n",
        "\n",
        "x = df.iloc[:, :-2].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(x, axis=0)\n",
        "std = np.std(x, axis=0)+ 1e-8\n",
        "\n",
        "x1 = (x - mean) / std\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x1, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nTQmFSLy1Of"
      },
      "source": [
        "verifico il mio codice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NgrF3dqHkNHk"
      },
      "outputs": [],
      "source": [
        "net = NNC(x_train.shape[1], 6, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg4lCBk9mOOG"
      },
      "outputs": [],
      "source": [
        "net.fit(x_train, y_train, lr=0.1, epochs=5000)\n",
        "predizione = net.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXD3lLdGy6vB"
      },
      "source": [
        "verifico l'accuratezza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKC1dWVUqTQl"
      },
      "outputs": [],
      "source": [
        "predizione =np.max(predizione, axis=1)\n",
        "print(accuracy(y_test, predizione)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visA8n8CzCua"
      },
      "source": [
        "verifico anche con sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWb95cAozFff"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clfc = MLPClassifier(6, max_iter=1000, random_state=42)\n",
        "\n",
        "clfc.fit(x_train, y_train)\n",
        "\n",
        "predicted_class = clfc.predict(x_test)\n",
        "\n",
        "print(accuracy(y_test, predicted_class)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY96okkciTIQ"
      },
      "source": [
        "# Resoconto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRF6z-G5KW_K"
      },
      "source": [
        "Ora descrivo brevemente i modelli sviluppati, alcuni accorgimenti che ho adottato e i risultati ottenuti. **Ho però descritto nel dettaglio ogni codice con la logica dietro il codice e le varie funzioni usate nel dettaglio in ogni sezione prima di scrivere il codice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADhWECBNiWWn"
      },
      "source": [
        "**Classificazione:** Per la classificazione sono stati usati vari metodi tra cui Decision Trees (sviluppato come una classificazione), Classificazione con regressione lineare, Classificazione con regressione logistica, Classificazione con algoritmo di k-Nearest Neighbors e Classificazione con Reti Neurali.\n",
        "Tutti i codici sono stati valutati tramite una funzione accuracy:\n",
        "\n",
        "$$\n",
        "\\frac{TP+TN}{TP+TN+FP+FN}\n",
        "$$\n",
        "\n",
        "e poi paragonati al codice preso dalla libreria sklearn. In questi casi (tranne negli alberi dove non avevo problemi di overflow e non avevo miglioramenti di accuracy) ho deciso di normalizzare i dati delle feature e solo dopo dividerli in test e train.\n",
        "In questo modo sono riuscito a migliorare la mia accuracy e evitare problemi di overflow specialmente nei casi in cui veniva usata la funzione sigmoide ed inoltre è un processo molto importante per garantire un'adeguata preparazione dei dati prima dell'addestramento del modello migliorando le sue performance e migliorando la generalizzazione.\n",
        "Per quanto riguarda i livelli di accuratezza sono tutti maggiori del 52%.\n",
        "Ho avuto risultati migliori e stabili (cambiando spesso i dati di test e train), con la classificazione con regressione logistica dove ho ottenuto un accuracy sul 63% e anche con k-Nearest Neighbors sempre superiore al 60% (testata con k=5) ma impiega molto più tempo ad arrivare al risultato rispetto agli altri metodi. Per utlimo ho provato a realizzare la classificazione tramite Reti Neurali usando una rete neurale a tre strati (uno solo hidden) con due funzioni di attivazione (uno tra il primo e secondo strato e uno tra il secondo e il terzo) rispettivamente la funzione ReLu e sigmoide.\n",
        "In questi casi l'accuracy supera sempre il 52% ma i risultati dipendono molto dai dati di test e train ma arriva spesso sopra il 60%, l'unico problema del codice è un errore: *RuntimeWarning: overflow encountered* nel calcolo della sigmoide che però non interferisce nel portare a termine il codice.\n",
        "Resoconto risultati accuracy (mio codice e sklearn)\n",
        "\n",
        "* Alberi 63%  58%                                  \n",
        "* Linear Classification 56%  56%\n",
        "* Con regressione logistica 66% 65%\n",
        "* K-NN  61% 61%\n",
        "* Reti neurali 52/65% 66%\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAYRbKgeicaL"
      },
      "source": [
        "**Regressione:** nel caso della regressione ho implementato i seguenti modelli:\n",
        "Regressione lineare (senza regolarizzazione, regolarizzazione L1, L2, e elastic net)\n",
        "Regressione con algoritmo di k-Nearest Neighbors e Regressione con Reti Neurali.\n",
        "Sono stati tutti valutati tramite il calcolo del RMSE:\n",
        "\n",
        "$$\n",
        "\\sqrt{\\frac{1}{n}\\sum\\limits_{i=1}^{n}{\\Big(d_i -f_i\\Big)^2}}\n",
        "$$\n",
        "\n",
        "Anche nel  caso della regressione ho normalizzato le x ma nel caso delle reti neurlai per la regressione ho deciso dopo vari tentativi di normalizzare anche le y.\n",
        "Nel caso della regressione con le reti neurali ho che  la rmse esce abbastanza stabile con valori prossimi a 0.68 (il valore cosi basso è dovuto al fatto che anche i valori di y_train sono normalizzati), prima di normalizzare anche le y avevo provato ad usare due hidden layer poichè i risultati variavano molto in base ai dati di test ma non migliorava molto poichè dovevo inserire un learning rate molto basso per evitare overflow, ma normalizzando y ho risolto tutti i problemi.\n",
        "Per K-Nearest Neighbors ho ottenuto un valore di rmse di 8800 circa simile a quello ottenuto usando sklearn con k=5 ma anche qui i tempi sono un po' più lunghi rispetto agli altri modelli.\n",
        "Nel caso di Linear Regression ho scritto due codici uno senza regolarizzazione che ha ottenuto un rmse di circa 7700 (simile a quello di sklear). Per evitare overfitting (il modello non generalizza bene su nuovi dati non visti) si usa la regolarizzazione nel mio caso ho scritto un solo codice in cui poi è possibile decidere il tipo di regolarizzazione tra L1, L2 e elastic net i risultati di tali modelli restano comunque coerenti con quelli che ho ottenuto senza regolarizzazione.\n",
        "Resoconto risultati RMSE (mio codice e sklearn)\n",
        "* Linear Regression:\n",
        "    1. Senza Regolarizzazione 7664,2 - 7643\n",
        "    2. L1 7644,36 - 7644,8\n",
        "    3. L2 7644,37 - 7643,5\n",
        "    4. Elastic Net 7662 - 7644,8\n",
        "\n",
        "* K-NN 8863  - 8863\n",
        "* Reti neurali 0,67 - 0,66\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mu_rxzq0f2gV",
        "UreUUCYinWBT",
        "T0U_QCzFhcNJ",
        "nD-c_U5U1J7o",
        "CuRF1fApmLKN",
        "PTAfW3efQHdX",
        "elD3uZ2oclHj",
        "sDlj_YMQ2Ine",
        "--IfXnLpcnql",
        "O1OaXxSmcrZZ"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}